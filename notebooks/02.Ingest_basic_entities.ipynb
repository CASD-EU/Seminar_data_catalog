{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#  Ingest metadata of basic entities into open metadata\n",
    "\n",
    "In this tutorial, we will show how to ingest metadata into open metadata.\n",
    "\n",
    "There are many ways to ingest metadat into openmetadata, such as:\n",
    "- connectors\n",
    "- rest API\n",
    "- python SDK\n",
    "\n",
    "In this tutorial, we only how you how to use `python SDK` to ingest metadata.\n",
    "\n",
    "## 1. Set up the python virtual environment\n",
    "\n",
    "Open a conda shell of **python 11** in `Bureau`->`Raccourci`->`Python`. Then enter the below command\n",
    "\n",
    "```shell\n",
    "# 1. Check if conda exists in the current shell\n",
    "conda --version\n",
    "\n",
    "# 2. create a virtual environment\n",
    "conda create --name om-ingestion python --offline\n",
    "# view existing virtual environment list\n",
    "conda env list\n",
    "# check status of a virtual environment\n",
    "conda info --envs\n",
    "\n",
    "# 3. activate a virtual environment\n",
    "conda activate om-ingestion\n",
    "\n",
    "# 4. install packages\n",
    "# check installed package list\n",
    "pip list\n",
    "\n",
    "# install package via requirements.txt\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# 5. verify that you have the required packages\n",
    "pip show pandas\n",
    "pip show openmetadata-ingestion\n",
    "```\n",
    "\n",
    "## 2. Ingest metadata of basic entities\n",
    "\n",
    "The most basic entities in open metadata is the descriptive metadata of data assets. For example\n",
    "- Databases\n",
    "- Tables\n",
    "- Columns\n",
    "- Filesystem\n",
    "- Folder\n",
    "- Files\n",
    "- Etc.\n",
    "\n",
    "In the below example, we will insert the descriptive metadata of Database, Schema, tables, and columns."
   ],
   "id": "7c7b3379c5ec65f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:06:55.504826Z",
     "start_time": "2025-09-08T16:06:50.172466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from metadata.ingestion.ometa.ometa_api import OpenMetadata\n",
    "from metadata.generated.schema.entity.services.connections.metadata.openMetadataConnection import (OpenMetadataConnection, AuthProvider)\n",
    "from metadata.generated.schema.security.client.openMetadataJWTClientConfig import OpenMetadataJWTClientConfig"
   ],
   "id": "f59f3e090c31d200",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Check open metadata api server connectivity\n",
    "\n",
    "The python-SDK which we use to ingest metadata is an `OM client`, it needs to connect to an `OM server` to ingest metadata.\n",
    "Let's check the connectivity of the server via client."
   ],
   "id": "bc7939334469c9fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:06:58.037668Z",
     "start_time": "2025-09-08T16:06:58.034219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you need to modify this value to match your target open metadata server url\n",
    "target_om_server=\"http://om-dev.casd.local/api\""
   ],
   "id": "d5ff1a7166ad9e46",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:06:58.905383Z",
     "start_time": "2025-09-08T16:06:58.863651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from conf.creds import om_oidc_token\n",
    "server_config = OpenMetadataConnection(\n",
    "    hostPort=target_om_server,\n",
    "    authProvider=AuthProvider.openmetadata,\n",
    "    securityConfig=OpenMetadataJWTClientConfig(\n",
    "        jwtToken=om_oidc_token,\n",
    "    ),\n",
    ")\n",
    "om_con = OpenMetadata(server_config)"
   ],
   "id": "affb21bdd19c3819",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:06:59.626218Z",
     "start_time": "2025-09-08T16:06:59.607418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if it returns true, it means the connection is success \n",
    "om_con.health_check()"
   ],
   "id": "2a8a9344aed2cea3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Ingest the metadata of a database\n",
    "\n",
    "Suppose we have a mysql database called `hospitals_in_france`. We want to ingest metadata of this database into OM. So other users can use this database."
   ],
   "id": "916b5af61a02ce9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:03.828206Z",
     "start_time": "2025-09-08T13:39:03.749050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.services.createDatabaseService import CreateDatabaseServiceRequest\n",
    "from metadata.generated.schema.entity.services.connections.database.common.basicAuth import BasicAuth\n",
    "from metadata.generated.schema.entity.services.connections.database.mysqlConnection import MysqlConnection\n",
    "from metadata.generated.schema.entity.services.databaseService import (DatabaseConnection, DatabaseService, DatabaseServiceType,)\n",
    "\n",
    "# name of the db service\n",
    "DB_SERVICE_NAME = \"Constances-Geography\"\n",
    "# description of the service\n",
    "DB_SERVICE_DESC = \"This database service stores all geography databases of INSERM\"\n",
    "\n",
    "DB_AUTH_LOGIN = \"db_login\"\n",
    "DB_AUTH_PWD = \"db_pwd\"\n",
    "DB_URL = \"http://db_url:1234\"\n",
    "\n",
    "db_service = CreateDatabaseServiceRequest(\n",
    "    name=DB_SERVICE_NAME,\n",
    "    serviceType=DatabaseServiceType.Mysql,\n",
    "    connection=DatabaseConnection(\n",
    "        config=MysqlConnection(\n",
    "            username=DB_AUTH_LOGIN,\n",
    "            authType=BasicAuth(password=DB_AUTH_PWD),\n",
    "            hostPort=DB_URL,\n",
    "        )\n",
    "    ),\n",
    "    description=DB_SERVICE_DESC,\n",
    ")\n",
    "\n",
    "# when we create an entity by using function `create_or_update`, it returns the created instance of the query\n",
    "db_service_entity = om_con.create_or_update(data=db_service)"
   ],
   "id": "2e37614cb861d481",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:05.213138Z",
     "start_time": "2025-09-08T13:39:05.206059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can view the content of the returned object to check if your request is executed correctly.\n",
    "print(db_service_entity)"
   ],
   "id": "c6edef46d810807a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=Uuid(root=UUID('c726e413-a5de-41d0-a9b7-25fb11197d6b')) name=EntityName(root='Constances-Geography') fullyQualifiedName=FullyQualifiedEntityName(root='Constances-Geography') displayName=None serviceType=<DatabaseServiceType.Mysql: 'Mysql'> description=Markdown(root='This database service stores all geography databases of INSERM') connection=DatabaseConnection(config=MysqlConnection(type=<MySQLType.Mysql: 'Mysql'>, scheme=<MySQLScheme.mysql_pymysql: 'mysql+pymysql'>, username='db_login', authType=BasicAuth(password=SecretStr('**********')), hostPort='http://db_url:1234', databaseName=None, databaseSchema=None, sslConfig=None, connectionOptions=None, connectionArguments=None, schemaFilterPattern=FilterPattern(includes=[], excludes=['^information_schema$', '^performance_schema$']), tableFilterPattern=None, databaseFilterPattern=None, supportsMetadataExtraction=SupportsMetadataExtraction(root=True), supportsDBTExtraction=SupportsDBTExtraction(root=True), supportsProfiler=SupportsProfiler(root=True), supportsQueryComment=SupportsQueryComment(root=True), sampleDataStorageConfig=None, supportsDataDiff=SupportsDataDiff(root=True), supportsUsageExtraction=SupportsUsageExtraction(root=True), supportsLineageExtraction=SupportsLineageExtraction(root=True), useSlowLogs=False)) pipelines=None testConnectionResult=None tags=[] version=EntityVersion(root=0.2) updatedAt=Timestamp(root=1757338743781) updatedBy='ingestion-bot' owners=EntityReferenceList(root=[]) href=Href(root=AnyUrl('http://localhost:8585/v1/services/databaseServices/c726e413-a5de-41d0-a9b7-25fb11197d6b')) followers=None changeDescription=ChangeDescription(fieldsAdded=[], fieldsUpdated=[FieldChange(name=FieldName(root='connection'), oldValue='\"old-encrypted-value\"', newValue='\"new-encrypted-value\"')], fieldsDeleted=[], previousVersion=EntityVersion(root=0.1), changeSummary=ChangeSummaryModel(root={})) incrementalChangeDescription=ChangeDescription(fieldsAdded=[], fieldsUpdated=[FieldChange(name=FieldName(root='connection'), oldValue='\"old-encrypted-value\"', newValue='\"new-encrypted-value\"')], fieldsDeleted=[], previousVersion=EntityVersion(root=0.1), changeSummary=ChangeSummaryModel(root={})) deleted=False dataProducts=None domains=None ingestionRunner=None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:07.484609Z",
     "start_time": "2025-09-08T13:39:07.424351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.data.createDatabase import CreateDatabaseRequest\n",
    "DB_NAME = \"hospitals_in_france\"\n",
    "\n",
    "db_entity_req = CreateDatabaseRequest(\n",
    "    name=DB_NAME,\n",
    "    service=db_service_entity.fullyQualifiedName,\n",
    "    description=\"In this database, we store all tables which contain geographical information in Constances\",\n",
    ")\n",
    "\n",
    "db_entity = om_con.create_or_update(data=db_entity_req)"
   ],
   "id": "70856d7e4a869e6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:10.167559Z",
     "start_time": "2025-09-08T13:39:10.087311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.data.createDatabaseSchema import CreateDatabaseSchemaRequest\n",
    "SCHEMA_NAME = \"Geography\"\n",
    "create_schema_req = CreateDatabaseSchemaRequest(\n",
    "    name=SCHEMA_NAME, \n",
    "    database=db_entity.fullyQualifiedName,\n",
    "    description=\"In this schema, we group all tables which contain geographical information of hospitals in France\",)\n",
    "\n",
    "# the create request will return the fqn(fully qualified name) of the created schema\n",
    "schema_entity = om_con.create_or_update(data=create_schema_req)"
   ],
   "id": "3b0d61d6d7f53636",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step2: Get metadata from source files\n",
    "\n",
    "Here we use two files to describe metadata:\n",
    "- <project_name>_tables: describes the metadata of tables in this project\n",
    "- <project_name_vars>: describes the metadata of the columns in this project "
   ],
   "id": "70b622ba52b61c33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:20.982473Z",
     "start_time": "2025-09-08T13:39:20.975116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "project_root = pathlib.Path.cwd().parent\n",
    "metadata_path = project_root / \"data\"\n",
    "\n",
    "print(metadata_path)"
   ],
   "id": "d8d4f57e7e7921c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLIU\\Documents\\git\\Seminare_data_catalog\\data\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:21.576875Z",
     "start_time": "2025-09-08T13:39:21.573298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_spec_path = f\"{metadata_path}/constances_tables.csv\"\n",
    "col_spec_path = f\"{metadata_path}/constances_vars.csv\"\n",
    "\n"
   ],
   "id": "69330e6c60b62cd7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:22.423182Z",
     "start_time": "2025-09-08T13:39:22.374018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_df = pd.read_csv(table_spec_path,header=0)\n",
    "print(table_df.head(5))"
   ],
   "id": "6711b2784ba2c72e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       domain                  table  \\\n",
      "0       INSEE        fr_communes_raw   \n",
      "1  Constances      fr_communes_clean   \n",
      "2         OSM         osm_france_raw   \n",
      "3  Constances    osm_hospitals_clean   \n",
      "4  Constances  hospitals_in_communes   \n",
      "\n",
      "                                         description  creation  suppression  \n",
      "0  This table contains all geographical informati...      2022          NaN  \n",
      "1  This table is built based on fr_communes_raw w...      2024          NaN  \n",
      "2  This table is the open street map of france. I...      2020          NaN  \n",
      "3  This table is build based on osm_france_raw. I...      2024          NaN  \n",
      "4  This table contains the number of hospitals in...      2024          NaN  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:23.302186Z",
     "start_time": "2025-09-08T13:39:23.274126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "col_df = pd.read_csv(col_spec_path,header=0)\n",
    "print(col_df.head(5))"
   ],
   "id": "1dea237874908789",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             table        var                                    description  \\\n",
      "0  fr_communes_raw   geometry  geo location of the commune in a polygon form   \n",
      "1  fr_communes_raw  wikipedia            url of the wiki page of the commune   \n",
      "2  fr_communes_raw    surf_ha          number of habitats inside the commune   \n",
      "3  fr_communes_raw        nom                            name of the commune   \n",
      "4  fr_communes_raw      insee                      code insee of the commune   \n",
      "\n",
      "   var_type var_size    nomencalure  creation  suppression  \n",
      "0  geometry       18  geometry_type      2024          NaN  \n",
      "1    string       28            NaN      2024          NaN  \n",
      "2    number        8            NaN      2024          NaN  \n",
      "3    string       26            NaN      2024          NaN  \n",
      "4    string        5     code_insee      2024          NaN  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:24.273687Z",
     "start_time": "2025-09-08T13:39:24.260020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.data.createTable import CreateTableRequest\n",
    "from metadata.generated.schema.entity.data.table import Column, DataType\n",
    "\n",
    "def getColDetailsByTabName(table_name:str, col_df):\n",
    "    # filter the rows that belongs to the given table name\n",
    "    table_col_list=col_df[col_df[\"table\"]==table_name].to_dict(orient=\"records\")\n",
    "    return table_col_list\n",
    "    \n",
    "target_tab_name = \"fr_communes_raw\"\n",
    "tab_col_list=getColDetailsByTabName(target_tab_name, col_df)\n",
    "\n",
    "for item in tab_col_list:\n",
    "    print(f\"table name: {item['table']}\")\n",
    "    print(f\"column name: {item['var']}\")\n",
    "    print(f\"column type: {item['var_type']}\")\n",
    "    print(f\"column size: {item['var_size']}\")\n",
    "    print(f\"column description: {item['description']}\")"
   ],
   "id": "9fdaa20baae10c5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table name: fr_communes_raw\n",
      "column name: geometry\n",
      "column type: geometry\n",
      "column size: 18\n",
      "column description: geo location of the commune in a polygon form\n",
      "table name: fr_communes_raw\n",
      "column name: wikipedia\n",
      "column type: string\n",
      "column size: 28\n",
      "column description: url of the wiki page of the commune\n",
      "table name: fr_communes_raw\n",
      "column name: surf_ha\n",
      "column type: number\n",
      "column size: 8\n",
      "column description: number of habitats inside the commune\n",
      "table name: fr_communes_raw\n",
      "column name: nom\n",
      "column type: string\n",
      "column size: 26\n",
      "column description: name of the commune\n",
      "table name: fr_communes_raw\n",
      "column name: insee\n",
      "column type: string\n",
      "column size: 5\n",
      "column description: code insee of the commune\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3. clean the metadata before ingestion  \n",
    "\n",
    "We need to clean the raw metadata before ingestion, because the value may not be compatible with `Open metadata`.\n",
    "For example, the column types in `Open metadata` are pre-defined. Only the valid value can be inserted into the `Open metadata` server. "
   ],
   "id": "9eb1a594613849ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:31.790004Z",
     "start_time": "2025-09-08T13:39:31.774586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.entity.data.table import Column, DataType\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# util func\n",
    "authorized_str_type=[\"string\",\"str\",]\n",
    "authorized_int_type=[\"int\",\"integer\"]\n",
    "authorized_long_type=[\"bigint\",\"long\"]\n",
    "\n",
    "def get_om_dtype(in_type:str)->DataType:\n",
    "    # test input type is not null and is string\n",
    "    if in_type and isinstance(in_type, str):\n",
    "        # cast it to lower case to ignor case\n",
    "        in_type_val=in_type.lower()\n",
    "        # we create a mapping case for all sql types\n",
    "        if in_type_val == \"tinyint\":\n",
    "            return DataType.TINYINT\n",
    "        elif in_type_val == \"byte\":\n",
    "            return DataType.BYTEINT\n",
    "        elif in_type_val == \"smallint\":\n",
    "            return DataType.SMALLINT\n",
    "        elif in_type_val in authorized_int_type:\n",
    "            return DataType.INT\n",
    "        elif in_type_val in authorized_long_type:\n",
    "            return DataType.BIGINT\n",
    "        elif in_type_val=='numeric':\n",
    "            return DataType.NUMERIC\n",
    "        elif in_type_val=='number':\n",
    "            return DataType.NUMBER\n",
    "        elif in_type_val=='float':\n",
    "            return DataType.FLOAT\n",
    "        elif in_type_val=='double':\n",
    "            return DataType.DOUBLE\n",
    "        elif in_type_val=='date':\n",
    "            return DataType.DATE\n",
    "        elif in_type_val=='time':\n",
    "            return DataType.TIME\n",
    "        elif in_type_val==\"char\":\n",
    "            return DataType.CHAR\n",
    "        elif in_type_val==\"varchar\":\n",
    "            return DataType.VARCHAR\n",
    "        elif in_type_val==\"text\":\n",
    "            return DataType.TEXT\n",
    "        elif in_type_val==\"ntext\":\n",
    "            return DataType.NTEXT\n",
    "        elif in_type_val==\"binary\":\n",
    "            return DataType.BINARY\n",
    "        elif in_type_val==\"varbinary\":\n",
    "            return DataType.VARBINARY\n",
    "        # other types\n",
    "        elif in_type_val in authorized_str_type:\n",
    "            return DataType.STRING\n",
    "        # for complex map such as array<int>, map<int,string>\n",
    "        # we must use dataTypeDisplay to show the details. In dataType, we can only put array, map\n",
    "        elif in_type_val==\"array\":\n",
    "            return DataType.ARRAY\n",
    "        elif in_type_val==\"map\":\n",
    "            return DataType.MAP\n",
    "        elif in_type_val==\"struct\":\n",
    "            return DataType.STRUCT\n",
    "        # for geometry type\n",
    "        elif in_type_val==\"geometry\":\n",
    "            return DataType.GEOMETRY\n",
    "        # for empty string, we use string as default value\n",
    "        elif in_type_val==\"\":\n",
    "            return DataType.STRING\n",
    "        \n",
    "        else:\n",
    "            return DataType.UNKNOWN\n",
    "    else:\n",
    "        print(f\"The input value {in_type} is not a valid string type\")\n",
    "        raise ValueError\n",
    "    \n",
    "\n",
    "def build_type_display_name(type_val: str, length: Optional[int], precision: Optional[int]) -> str:\n",
    "    \"\"\"\n",
    "    This function build a data type display value, it only considers three case, because the result return by \n",
    "    split_length_precision only has three possible case\n",
    "    :param type_val: data type value (e.g. string, int, etc.) \n",
    "    :type type_val: str\n",
    "    :param length: full length of the type \n",
    "    :type length: Optional[int]\n",
    "    :param precision: precision of the type \n",
    "    :type precision: Optional[int]\n",
    "    :return: data type display value\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if length and precision:\n",
    "        return f\"{type_val}({length},{precision})\"\n",
    "    elif length and not precision:\n",
    "        return f\"{type_val}({length})\"\n",
    "    else:\n",
    "        return type_val\n",
    "\n",
    "def split_length_precision(raw_type_size: str) -> (int, int):\n",
    "    \"\"\"\n",
    "    This function parse the raw type size (e.g. 3 or 5,3) into a tuple of (length, precision).\n",
    "    Some example\n",
    "     - 3 to (3,None)\n",
    "     - 5,3 to (5,3).\n",
    "     - None or not string to (None,None)\n",
    "     - \"\" to (None,None)\n",
    "     - ,3 to (None,None) because it does not make sense if only return precision\n",
    "    :param raw_type_size:\n",
    "    :type raw_type_size:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    length = None\n",
    "    precision = None\n",
    "    # if it's null or not string, return none,none\n",
    "    if raw_type_size and isinstance(raw_type_size, str):\n",
    "        # if the size is not empty string, do split\n",
    "        if len(raw_type_size) > 0:\n",
    "            split_res = raw_type_size.split(\",\", 1)\n",
    "            # if it has two items after split, it has length and precision\n",
    "            try:\n",
    "                if len(split_res) == 2:\n",
    "                    length = int(split_res[0])\n",
    "                    precision = int(split_res[1])\n",
    "                else:\n",
    "                    length = int(split_res[0])\n",
    "            except ValueError as e:\n",
    "                print(f\"The length:{split_res[0]} or precision{split_res[1]} can't be cast to int.\")\n",
    "\n",
    "    return length, precision\n",
    "    \n",
    "def generate_om_column_entity(col_details:List[Dict])->List[Column]:\n",
    "    \"\"\"\n",
    "    This functions takes the column details of a tables, it generates a list of openmetadata column entity\n",
    "    :param col_details: \n",
    "    :type col_details: \n",
    "    :return: \n",
    "    :rtype: \n",
    "    \"\"\"\n",
    "    columns:List[Column]=[]\n",
    "    for col_detail in col_details:\n",
    "        col_name=col_detail['var']\n",
    "        type_val=col_detail['var_type'].lower()\n",
    "        type_size=col_detail['var_size']\n",
    "        length, precision=split_length_precision(type_size)\n",
    "        data_type=get_om_dtype(type_val)\n",
    "        type_display_val=build_type_display_name(type_val,length,precision)\n",
    "        col_desc=col_detail['description']\n",
    "        # for array data type, we must also provide the datatype inside the array, here we set string for simplicity\n",
    "        if data_type==DataType.ARRAY:\n",
    "            array_data_type=DataType.STRING\n",
    "        else:\n",
    "            array_data_type=None\n",
    "        # for struct data type,\n",
    "        if data_type==DataType.STRUCT:\n",
    "            children=[{\"version\":DataType.INT},{\"timestamp\":DataType.TIME}]\n",
    "        else:\n",
    "            children=None\n",
    "        col_entity=Column(name=col_name, dataType=data_type, arrayDataType=array_data_type, children=children, dataTypeDisplay=type_display_val, dataLength=length,precision=precision,description=col_desc)\n",
    "        columns.append(col_entity)\n",
    "    return columns"
   ],
   "id": "977b30bed9bf7f6c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:39:32.924670Z",
     "start_time": "2025-09-08T13:39:32.504571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Load metadata of all tables\n",
    "from metadata.generated.schema.api.data.createTable import CreateTableRequest\n",
    "# step1: loop the table list to get table name and description\n",
    "table_list=table_df[['table','description']].to_dict(orient=\"records\")\n",
    "\n",
    "for tab in table_list:\n",
    "    tab_name=tab['table']\n",
    "    tab_desc=tab['description']\n",
    "    print(f\"tab_name:{tab_name}, tab_desc:{tab_desc}\")\n",
    "    # step2: get tab col list\n",
    "    tab_col_list=getColDetailsByTabName(tab_name, col_df)\n",
    "    # step3: loop through the col list and build the OM colum list\n",
    "    columns = generate_om_column_entity(tab_col_list)\n",
    "    # step4: create table\n",
    "    table_create=CreateTableRequest(\n",
    "    name=tab_name,\n",
    "    description=tab_desc,\n",
    "    databaseSchema=schema_entity.fullyQualifiedName,\n",
    "    columns=columns)\n",
    "    table_entity=om_con.create_or_update(data=table_create)"
   ],
   "id": "6ac38aa593e6a7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab_name:fr_communes_raw, tab_desc:This table contains all geographical information of french communes\n",
      "tab_name:fr_communes_clean, tab_desc:This table is built based on fr_communes_raw which is suitable for Contances related analysis\n",
      "tab_name:osm_france_raw, tab_desc:This table is the open street map of france. It contains all geographical information such as roads hospitals in france\n",
      "tab_name:osm_hospitals_clean, tab_desc:This table is build based on osm_france_raw. It only contains geographical information of hospitals in france\n",
      "tab_name:hospitals_in_communes, tab_desc:This table contains the number of hospitals in each communes\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ingest metadata of a file system",
   "id": "76c9cb168808d5bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --------------- CONFIGURATION ---------------\n",
    "LOCAL_FOLDER = \"/constances\"\n",
    "STORAGE_SERVICE_NAME = \"Constances-Datalake\"\n",
    "CONTAINER_NAME = \"root\"\n",
    "\n",
    "# ---------------- CREATE STORAGE SERVICE ----------------\n",
    "def create_or_get_storage_service(om_server_con):\n",
    "    # Check if the wanted storage service already exists, return the service entity\n",
    "    service = om_server_con.get_by_name(entity=\"storageService\", fqn=STORAGE_SERVICE_NAME)\n",
    "    if service:\n",
    "        return service\n",
    "\n",
    "    custom_storage_conn = CustomStorageConnection(\n",
    "        type=\"CustomStorage\",\n",
    "        sourcePythonClass=\"metadata.ingestion.source.storage.local.LocalStorageSource\",\n",
    "        connectionOptions={\"configSource\": LOCAL_FOLDER, \"bucketName\": CONTAINER_NAME}\n",
    "    )\n",
    "    storage_conn_entity = StorageConnection(config=custom_storage_conn)\n",
    "\n",
    "    service_request = CreateStorageServiceRequest(\n",
    "        name=STORAGE_SERVICE_NAME,\n",
    "        serviceType=StorageServiceType.CustomStorage,\n",
    "        description=\"Local filesystem storage service\",\n",
    "        connection=storage_conn_entity\n",
    "    )\n",
    "\n",
    "    return om_server_con.create_or_update(data=service_request)\n",
    "\n",
    "# ---------------- CREATE ROOT CONTAINER ----------------\n",
    "def create_root_container(om_server_con, storage_service_entity):\n",
    "    container = om_server_con.get_by_name(entity=\"container\", fqn=f\"{STORAGE_SERVICE_NAME}.{CONTAINER_NAME}\")\n",
    "    if container:\n",
    "        return container\n",
    "\n",
    "    container_request = CreateContainerRequest(\n",
    "        name=CONTAINER_NAME,\n",
    "        displayName=\"Root Container\",\n",
    "        service=storage_service_entity.fullyQualifiedName,\n",
    "        dataModel=ContainerDataModel(isPartitioned=False)\n",
    "    )\n",
    "    return om_server_con.create_or_update(data=container_request)\n",
    "\n",
    "# ---------------- CREATE FILE ENTITIES ----------------\n",
    "# def register_files(om_server_con, storage_service_entity, container_entity, folder_path):\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         for f in files:\n",
    "#             file_path = os.path.join(root, f)\n",
    "#             size = os.path.getsize(file_path)\n",
    "#             ext = os.path.splitext(f)[1]\n",
    "#             mime = \"text/csv\" if ext == \".csv\" else None  # simple heuristic\n",
    "#             file_request = CreateFileRequest(\n",
    "#                 name=f,\n",
    "#                 displayName=f,\n",
    "#                 service=storage_service_entity.fullyQualifiedName,\n",
    "#                 directory=container_entity.fullyQualifiedName,\n",
    "#                 fileType=FileType.CSV if ext==\".csv\" else FileType.Other,\n",
    "#                 mimeType=mime,\n",
    "#                 fileExtension=ext,\n",
    "#                 path=file_path,\n",
    "#                 size=size\n",
    "#             )\n",
    "#             om_server_con.create_or_update(data=file_request)\n",
    "#             print(f\"Registered file: {file_path}\")"
   ],
   "id": "7f7b049c640aba2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:07:20.157813Z",
     "start_time": "2025-09-08T16:07:20.080425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.services.createStorageService import CreateStorageServiceRequest\n",
    "from metadata.generated.schema.entity.services.storageService import StorageServiceType, StorageConnection\n",
    "from metadata.generated.schema.entity.services.connections.storage.customStorageConnection import \\\n",
    "    CustomStorageConnection, CustomStorageType\n",
    "\n",
    "from metadata.generated.schema.entity.services.storageService import StorageService\n",
    "\n",
    "# Step 1: Create the CustomStorageConnection\n",
    "custom_conn = CustomStorageConnection(\n",
    "    type=\"CustomStorage\",\n",
    "    sourcePythonClass=\"metadata.ingestion.source.storage.local.LocalStorageSource\",\n",
    "    connectionOptions={\n",
    "\n",
    "    }\n",
    ")\n",
    "#        \"configSource\": \"/data\",\n",
    "#         \"bucketName\": \"local-bucket\"\n",
    "\n",
    "# Step 2: Wrap it inside StorageConnection\n",
    "storage_conn = StorageConnection(config=custom_conn)\n",
    "\n",
    "# Step 3: Create StorageServiceRequest\n",
    "storage_service_request = CreateStorageServiceRequest(\n",
    "    name=\"Local-Filesystem\",\n",
    "    serviceType=StorageServiceType.CustomStorage,\n",
    "    displayName=\"Local Filesystem\",\n",
    "    description=\"Custom storage service for local files\",\n",
    "    connection=storage_conn  # <-- must be StorageConnection, not CustomStorageConnection directly\n",
    ")\n",
    "\n",
    "# Step 4: Create or update in OpenMetadata\n",
    "storage_service_entity = om_con.create_or_update(data=storage_service_request)\n",
    "print(f\"StorageService created: {storage_service_entity}\")"
   ],
   "id": "c49d31983e3ab053",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageService created: id=Uuid(root=UUID('36592ca7-8dda-4fbe-ab45-d31c592976a3')) name=EntityName(root='Local-Filesystem') fullyQualifiedName=FullyQualifiedEntityName(root='Local-Filesystem') displayName='Local Filesystem' serviceType=<StorageServiceType.CustomStorage: 'CustomStorage'> description=Markdown(root='Custom storage service for local files') connection=StorageConnection(config=CustomStorageConnection(type=<CustomStorageType.CustomStorage: 'CustomStorage'>, sourcePythonClass='metadata.ingestion.source.storage.local.LocalStorageSource', connectionOptions=ConnectionOptions(root={}), containerFilterPattern=None, supportsMetadataExtraction=SupportsMetadataExtraction(root=True))) pipelines=None testConnectionResult=None tags=[] version=EntityVersion(root=0.1) updatedAt=Timestamp(root=1757347640097) updatedBy='ingestion-bot' href=Href(root=AnyUrl('http://localhost:8585/v1/services/storageServices/36592ca7-8dda-4fbe-ab45-d31c592976a3')) owners=None changeDescription=None incrementalChangeDescription=None deleted=False dataProducts=None followers=None domains=None ingestionRunner=None\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:07:30.887582Z",
     "start_time": "2025-09-08T16:07:30.833642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.data.createContainer import CreateContainerRequest\n",
    "from metadata.generated.schema.entity.data.container import ContainerDataModel\n",
    "\n",
    "# 1. Create the root container (Drive)\n",
    "container_request = CreateContainerRequest(\n",
    "    name=\"local-bucket\",   # logical bucket name (must match your connectionOptions.bucketName if used)\n",
    "    displayName=\"Local Bucket\",\n",
    "    service=storage_service_entity.fullyQualifiedName,\n",
    "    dataModel=ContainerDataModel(\n",
    "        isPartitioned=False,\n",
    "        columns=[]\n",
    "    )\n",
    ")\n",
    "container_entity = om_con.create_or_update(data=container_request)\n",
    "print(f\"Container created: {container_entity.fullyQualifiedName}\")\n"
   ],
   "id": "87aa38221685eff6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container created: root='Local-Filesystem.local-bucket'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T16:11:46.741886Z",
     "start_time": "2025-09-08T16:11:46.627529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from metadata.generated.schema.api.data.createFile import CreateFileRequest\n",
    "from metadata.generated.schema.entity.data.file import FileType\n",
    "\n",
    "\n",
    "file_request = CreateFileRequest(\n",
    "    name=\"hospitals.csv\",\n",
    "    displayName=\"Hospitals in France\",\n",
    "    description=\"Dataset of French hospitals with location information\",\n",
    "    service=container_entity.fullyQualifiedName,      # points to the Container\n",
    "    fileType=FileType.CSV,\n",
    "    mimeType=\"text/csv\",\n",
    "    fileExtension=\".csv\",\n",
    "    path=\"/INSERM/geo/datasets/raw/hospitals.csv\",\n",
    "    size=123456,  # in bytes\n",
    "    checksum=\"d41d8cd98f00b204e9800998ecf8427e\",  # optional md5/sha1/sha256 hash\n",
    "    isShared=False,\n",
    "    fileVersion=\"v1.0\",\n",
    ")\n",
    "\n",
    "file_entity = om_con.create_or_update(data=file_request)\n",
    "print(f\"File created: {file_entity.fullyQualifiedName}\")\n"
   ],
   "id": "50233f670b6a0d8",
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "driveService instance for \"Local-Filesystem.local-bucket\" not found",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mHTTPError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\client.py:261\u001B[39m, in \u001B[36mREST._one_request\u001B[39m\u001B[34m(self, method, url, opts, retry)\u001B[39m\n\u001B[32m    260\u001B[39m resp = \u001B[38;5;28mself\u001B[39m._session.request(method, url, **opts)\n\u001B[32m--> \u001B[39m\u001B[32m261\u001B[39m \u001B[43mresp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    263\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resp.text != \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\requests\\models.py:1026\u001B[39m, in \u001B[36mResponse.raise_for_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1025\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response=\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[31mHTTPError\u001B[39m: 404 Client Error: Not Found for url: http://om-dev.casd.local/api/v1/drives/files",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mAPIError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmetadata\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgenerated\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mschema\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mentity\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfile\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileType\n\u001B[32m      5\u001B[39m file_request = CreateFileRequest(\n\u001B[32m      6\u001B[39m     name=\u001B[33m\"\u001B[39m\u001B[33mhospitals.csv\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      7\u001B[39m     displayName=\u001B[33m\"\u001B[39m\u001B[33mHospitals in France\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     fileVersion=\u001B[33m\"\u001B[39m\u001B[33mv1.0\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     18\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m file_entity = \u001B[43mom_con\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_or_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfile_request\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFile created: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_entity.fullyQualifiedName\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\ometa_api.py:341\u001B[39m, in \u001B[36mOpenMetadata.create_or_update\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    339\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_or_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: C) -> T:\n\u001B[32m    340\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Run a PUT requesting via create request C\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m341\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mput\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\ometa_api.py:328\u001B[39m, in \u001B[36mOpenMetadata._create\u001B[39m\u001B[34m(self, data, method)\u001B[39m\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidEntityException(\n\u001B[32m    324\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPUT operations need a CreateEntity, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mentity\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    325\u001B[39m     )\n\u001B[32m    327\u001B[39m fn = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.client, method)\n\u001B[32m--> \u001B[39m\u001B[32m328\u001B[39m resp = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# this might be a regular pydantic model so we build the context manually\u001B[39;49;00m\n\u001B[32m    330\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_suffix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentity\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_dump_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmask_secrets\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mby_alias\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m resp:\n\u001B[32m    334\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m EmptyPayloadException(\n\u001B[32m    335\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mGot an empty response when trying to PUT to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.get_suffix(entity)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata.model_dump_json()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    336\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\utils\\execution_time_tracker.py:195\u001B[39m, in \u001B[36mcalculate_execution_time.<locals>.decorator.<locals>.inner\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    192\u001B[39m execution_time = ExecutionTimeTracker()\n\u001B[32m    194\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m execution_time(context \u001B[38;5;129;01mor\u001B[39;00m func.\u001B[34m__name__\u001B[39m, store):\n\u001B[32m--> \u001B[39m\u001B[32m195\u001B[39m     result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\client.py:349\u001B[39m, in \u001B[36mREST.put\u001B[39m\u001B[34m(self, path, data)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;129m@calculate_execution_time\u001B[39m(context=\u001B[33m\"\u001B[39m\u001B[33mPUT\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    338\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mput\u001B[39m(\u001B[38;5;28mself\u001B[39m, path, data=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    339\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    340\u001B[39m \u001B[33;03m    PUT method\u001B[39;00m\n\u001B[32m    341\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    347\u001B[39m \u001B[33;03m        Response\u001B[39;00m\n\u001B[32m    348\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m349\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPUT\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\client.py:230\u001B[39m, in \u001B[36mREST._request\u001B[39m\u001B[34m(self, method, path, data, json, base_url, api_version, headers)\u001B[39m\n\u001B[32m    228\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m retry >= \u001B[32m0\u001B[39m:\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m230\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_one_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    231\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m LimitsException \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    232\u001B[39m         logger.error(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFeature limit exceeded for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminare_data_catalog\\dc_venv\\Lib\\site-packages\\metadata\\ingestion\\ometa\\client.py:287\u001B[39m, in \u001B[36mREST._one_request\u001B[39m\u001B[34m(self, method, url, opts, retry)\u001B[39m\n\u001B[32m    285\u001B[39m     error = resp.json()\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcode\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m error:\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m APIError(error, http_error) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mhttp_error\u001B[39;00m\n\u001B[32m    288\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    289\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mAPIError\u001B[39m: driveService instance for \"Local-Filesystem.local-bucket\" not found"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean up",
   "id": "ee2443979be2930f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T12:18:09.084555Z",
     "start_time": "2025-09-08T12:18:01.185744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# get database service id\n",
    "service_id = om_con.get_by_name(\n",
    "    entity=DatabaseService, fqn=DB_SERVICE_NAME\n",
    ").id\n",
    "\n",
    "# delete service by using id\n",
    "om_con.delete(\n",
    "    entity=DatabaseService,\n",
    "    entity_id=service_id,\n",
    "    recursive=True,\n",
    "    hard_delete=True,\n",
    ")"
   ],
   "id": "f58adb42567775ef",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T15:21:41.409870Z",
     "start_time": "2025-09-08T15:21:41.350300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get file system service id\n",
    "\n",
    "\n",
    "STORE_SER_NAME = \"Local-Filesystem\"\n",
    "storage_service_entity = om_con.get_by_name(\n",
    "    entity=StorageService, fqn=STORE_SER_NAME\n",
    ")\n",
    "print(storage_service_entity)"
   ],
   "id": "20549119fa56f219",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=Uuid(root=UUID('b9e113ba-2ea4-4d75-9713-38d90ce7bf98')) name=EntityName(root='Local-Filesystem') fullyQualifiedName=FullyQualifiedEntityName(root='Local-Filesystem') displayName='Local Filesystem' serviceType=<StorageServiceType.CustomStorage: 'CustomStorage'> description=Markdown(root='Local filesystem containing raw data files.') connection=StorageConnection(config=CustomStorageConnection(type=<CustomStorageType.CustomStorage: 'CustomStorage'>, sourcePythonClass='metadata.ingestion.source.storage.local.LocalStorageSource', connectionOptions=ConnectionOptions(root={'bucketName': 'local-bucket', 'configSource': '/data'}), containerFilterPattern=None, supportsMetadataExtraction=SupportsMetadataExtraction(root=True))) pipelines=None testConnectionResult=None tags=[] version=EntityVersion(root=0.2) updatedAt=Timestamp(root=1757340315204) updatedBy='ingestion-bot' href=Href(root=AnyUrl('http://localhost:8585/v1/services/storageServices/b9e113ba-2ea4-4d75-9713-38d90ce7bf98')) owners=None changeDescription=ChangeDescription(fieldsAdded=[FieldChange(name=FieldName(root='displayName'), oldValue=None, newValue='Local Filesystem')], fieldsUpdated=[FieldChange(name=FieldName(root='connection'), oldValue='\"old-encrypted-value\"', newValue='\"new-encrypted-value\"')], fieldsDeleted=[], previousVersion=EntityVersion(root=0.1), changeSummary=ChangeSummaryModel(root={})) incrementalChangeDescription=ChangeDescription(fieldsAdded=[FieldChange(name=FieldName(root='displayName'), oldValue=None, newValue='Local Filesystem')], fieldsUpdated=[FieldChange(name=FieldName(root='connection'), oldValue='\"old-encrypted-value\"', newValue='\"new-encrypted-value\"')], fieldsDeleted=[], previousVersion=EntityVersion(root=0.1), changeSummary=ChangeSummaryModel(root={})) deleted=False dataProducts=None followers=None domains=None ingestionRunner=None\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T15:22:13.471686Z",
     "start_time": "2025-09-08T15:22:10.718824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# delete service by using id\n",
    "om_con.delete(\n",
    "    entity=StorageService,\n",
    "    entity_id=storage_service_entity.id,\n",
    "    recursive=True,\n",
    "    hard_delete=True,\n",
    ")"
   ],
   "id": "1ffe8c25038a15ab",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ab394b7a8dd2a96"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
